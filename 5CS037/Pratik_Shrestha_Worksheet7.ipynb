{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mvVBYgGzYsX3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load dataset\n",
        "X, y = fetch_openml(\n",
        "    name=\"california_housing\",\n",
        "    version=1,\n",
        "    as_frame=True,\n",
        "    return_X_y=True,\n",
        "    parser=\"pandas\" # Ensures consistent dataframe handling\n",
        ")\n"
      ],
      "metadata": {
        "id": "n-M8XIKfs8E0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Preprocessing\n",
        "# Remove categorical feature as you intended\n",
        "X = X.drop(columns=[\"ocean_proximity\"])"
      ],
      "metadata": {
        "id": "_gKMJDows-5A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "def create_pipeline(model):\n",
        "    return Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')), # Fixes the NaN issue\n",
        "        ('scaler', StandardScaler()),                 # Scales data for regularization\n",
        "        ('regressor', model)\n",
        "    ])"
      ],
      "metadata": {
        "id": "O9zbtKFhtD1t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Baseline Linear Regression\n",
        "lr_pipe = create_pipeline(LinearRegression())\n",
        "lr_pipe.fit(X_train, y_train)\n",
        "print(f\"Baseline Test MSE: {mean_squared_error(y_test, lr_pipe.predict(X_test)):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MR848w7tJR_",
        "outputId": "d8ea77ee-9af8-4bef-a73c-e9bd857a49bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Test MSE: 5059656033.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Ridge with Cross-Validation\n",
        "ridge_pipe = create_pipeline(Ridge())\n",
        "ridge_cv = GridSearchCV(\n",
        "    ridge_pipe,\n",
        "    {'regressor__alpha': [0.1, 1, 10, 100]},\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error'\n",
        ")\n",
        "ridge_cv.fit(X_train, y_train)\n",
        "print(f\"Best Ridge alpha: {ridge_cv.best_params_['regressor__alpha']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cUnY6ZxtMuQ",
        "outputId": "155024a4-c42e-494b-be07-83a0d5a67e8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Ridge alpha: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Lasso with Cross-Validation\n",
        "lasso_pipe = create_pipeline(Lasso(max_iter=10000))\n",
        "lasso_cv = GridSearchCV(\n",
        "    lasso_pipe,\n",
        "    {'regressor__alpha': [0.1, 1, 10, 100]},\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error'\n",
        ")\n",
        "lasso_cv.fit(X_train, y_train)\n",
        "\n",
        "best_lasso = lasso_cv.best_estimator_.named_steps['regressor']\n",
        "print(f\"Best Lasso alpha: {lasso_cv.best_params_['regressor__alpha']}\")\n",
        "print(f\"Zero coefficients: {np.sum(best_lasso.coef_ == 0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iONjzueRtRSr",
        "outputId": "970e9f23-c0ad-4766-b32e-317bfcb5c4be"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Lasso alpha: 10\n",
            "Zero coefficients: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n"
      ],
      "metadata": {
        "id": "pTEJnDZ1tVEn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load data\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "def create_log_pipeline(penalty='l2', solver='lbfgs', C=1.0):\n",
        "    return Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('classifier', LogisticRegression(penalty=penalty, solver=solver, C=C, max_iter=10000))\n",
        "    ])"
      ],
      "metadata": {
        "id": "9cS0Y_FZugC9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Baseline Logistic Regression (No Penalty)\n",
        "log_reg = create_log_pipeline(penalty=None)\n",
        "log_reg.fit(X_train, y_train)\n",
        "print(f\"Baseline Accuracy: {accuracy_score(y_test, log_reg.predict(X_test)):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g_yMLa_unRP",
        "outputId": "0e35381c-8473-4b15-a726-fddb59994eb4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy: 0.9386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. L1 vs L2 Regularization\n",
        "log_l1 = create_log_pipeline(penalty='l1', solver='liblinear', C=0.5)\n",
        "log_l2 = create_log_pipeline(penalty='l2', solver='lbfgs', C=0.5)\n",
        "\n",
        "log_l1.fit(X_train, y_train)\n",
        "log_l2.fit(X_train, y_train)\n",
        "\n",
        "print(f\"L1 Accuracy:       {accuracy_score(y_test, log_l1.predict(X_test)):.4f}\")\n",
        "print(f\"L2 Accuracy:       {accuracy_score(y_test, log_l2.predict(X_test)):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sH5IzMhup_8",
        "outputId": "f67a11c2-fc59-4ef4-a7b0-3e95d8aeaa40"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 Accuracy:       0.9737\n",
            "L2 Accuracy:       0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Compare Sparsity (Feature Selection)\n",
        "l1_coefs = log_l1.named_steps['classifier'].coef_\n",
        "l2_coefs = log_l2.named_steps['classifier'].coef_\n",
        "\n",
        "print(f\"\\nL1 Zero Coefficients: {np.sum(l1_coefs == 0)} out of {l1_coefs.size}\")\n",
        "print(f\"L2 Zero Coefficients: {np.sum(l2_coefs == 0)} out of {l2_coefs.size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrKlCQvLut94",
        "outputId": "df04507e-2e32-43a1-8aae-8fc2ec2143c3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "L1 Zero Coefficients: 15 out of 30\n",
            "L2 Zero Coefficients: 0 out of 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-k26gwy6uwgF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}